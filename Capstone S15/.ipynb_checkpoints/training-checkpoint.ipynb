{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from MiDaS.depth_loss import compute_depth_loss\n",
    "from yolo_bbox_decoder.yolo_loss import compute_loss\n",
    "\n",
    "# garbage collection\n",
    "import gc\n",
    "\n",
    "mixed_precision = True\n",
    "try:  # Mixed precision training https://github.com/NVIDIA/apex\n",
    "    from apex import amp\n",
    "except:\n",
    "    # print('Apex recommended for mixed precision and faster training: https://github.com/NVIDIA/apex')\n",
    "    mixed_precision = False  # not installed\n",
    "\n",
    "from main_model import OpNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TSAIDataset, get_device\n",
    "\n",
    "train_dataset = TSAIDataset(\"D:\\\\data\\\\customdata\\\\train.txt\",(416, 416),\n",
    "                                                      is_training=True,data_dir_path = \"D:\\\\data\\\\customdata\\\\images\\\\\")\n",
    "\n",
    "test_dataset = TSAIDataset(\"D:\\\\data\\\\customdata\\\\test.txt\",(416, 416),\n",
    "                                                      is_training=False,data_dir_path = \"D:\\\\data\\\\customdata\\\\images\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[0.67843, 0.68235, 0.68235,  ..., 0.75686, 0.74510, 0.74118],\n",
       "          [0.67843, 0.68235, 0.68627,  ..., 0.75686, 0.74902, 0.74902],\n",
       "          [0.68235, 0.68627, 0.68627,  ..., 0.76078, 0.76078, 0.76078],\n",
       "          ...,\n",
       "          [0.19608, 0.19608, 0.19608,  ..., 0.19608, 0.19608, 0.19608],\n",
       "          [0.19608, 0.19608, 0.19608,  ..., 0.19608, 0.19608, 0.19608],\n",
       "          [0.19608, 0.19608, 0.19608,  ..., 0.19608, 0.19608, 0.19608]],\n",
       " \n",
       "         [[0.63922, 0.64314, 0.64314,  ..., 0.74902, 0.73725, 0.73333],\n",
       "          [0.63922, 0.64314, 0.64706,  ..., 0.74902, 0.74118, 0.74118],\n",
       "          [0.64314, 0.64706, 0.64706,  ..., 0.75294, 0.75294, 0.75294],\n",
       "          ...,\n",
       "          [0.20000, 0.20000, 0.20000,  ..., 0.20000, 0.20000, 0.20000],\n",
       "          [0.20000, 0.20000, 0.20000,  ..., 0.20000, 0.20000, 0.20000],\n",
       "          [0.20000, 0.20000, 0.20000,  ..., 0.20000, 0.20000, 0.20000]],\n",
       " \n",
       "         [[0.63529, 0.63922, 0.63922,  ..., 0.75294, 0.74118, 0.73725],\n",
       "          [0.63529, 0.63922, 0.64314,  ..., 0.75294, 0.74510, 0.74510],\n",
       "          [0.63922, 0.64314, 0.64314,  ..., 0.75686, 0.75686, 0.75686],\n",
       "          ...,\n",
       "          [0.28235, 0.28235, 0.28235,  ..., 0.28235, 0.28235, 0.28235],\n",
       "          [0.28235, 0.28235, 0.28235,  ..., 0.28235, 0.28235, 0.28235],\n",
       "          [0.28235, 0.28235, 0.28235,  ..., 0.28235, 0.28235, 0.28235]]]),\n",
       " 'label': tensor([[0.00000, 0.41833, 0.21127, 0.20111, 0.20070],\n",
       "         [2.00000, 0.43778, 0.39701, 0.11556, 0.15669],\n",
       "         [1.00000, 0.38722, 0.68134, 0.47000, 0.41197],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000],\n",
       "         [0.00000, 0.00000, 0.00000, 0.00000, 0.00000]]),\n",
       " 'image_path': 'D:\\\\data\\\\customdata\\\\images\\\\img_001.jpg',\n",
       " 'origin_size': '[900, 568]',\n",
       " 'depth': array([[ 27,  26,  26, ...,  38,  37,  35],\n",
       "        [ 27,  26,  26, ...,  38,  38,  36],\n",
       "        [ 27,  26,  26, ...,  37,  37,  38],\n",
       "        ...,\n",
       "        [239, 239, 241, ..., 173, 173, 175],\n",
       "        [240, 239, 240, ..., 172, 173, 175],\n",
       "        [241, 239, 239, ..., 172, 173, 174]], dtype=uint8)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 416, 416])\n"
     ]
    }
   ],
   "source": [
    "# for sample in test_dataloader:\n",
    "    \n",
    "#     print(sample['image'].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "yolo_args = {\n",
    "   'batch_size' : 1,\n",
    "    'cfg' : './yolo_bbox_decoder/cfg/yolov3-custom.cfg',\n",
    "    'epochs' : 10,\n",
    "    'weights' : './yolov3-spp-ultralytics.pt',\n",
    "    'data' : 'data/customdata/custom.data' ,\n",
    "    'img_size' : [512,512,512] #[640,640,640]\n",
    "}\n",
    "\n",
    "\n",
    "midas_args = {\n",
    "    'input' :'./data/customdata/images',\n",
    "    'weights' : 'midas/model-f6b98070.pt'\n",
    "}\n",
    "\n",
    "\n",
    "loss_weightage = {\n",
    "    \n",
    "    'yolo' : 1,\n",
    "    'midas' : 1\n",
    "}\n",
    "\n",
    "from options import *\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "yolo_args = yolo_parse_args()\n",
    "yolo_args.batch_size = 1\n",
    "yolo_args.cfg = 'yolo_bbox_decoder/cfg/yolov3-custom.cfg'\n",
    "yolo_args.epochs = 10\n",
    "yolo_args.weights = './yolov3-spp-ultralytics.pt'\n",
    "yolo_args.data = './data/customdata/custom.data'\n",
    "yolo_args.img_size=[512,512,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = yolo_args\n",
    "cfg = opt.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_pretrained True\n",
      "path midas/model-f6b98070.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\saina/.cache\\torch\\hub\\facebookresearch_WSL-Images_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "WARNING: smart bias initialization failure.\n",
      "Model Summary: 582 layers, 1.70705e+08 parameters, 1.70705e+08 gradients\n"
     ]
    }
   ],
   "source": [
    "from main_model import OpNet\n",
    "\n",
    "device = get_device(force_cpu=False)\n",
    "\n",
    "model = OpNet(yolo_cfg = yolo_args.cfg, midas_cfg = midas_args).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4be1bbfd208f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myolo_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmidas_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_weightage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\EVA-5\\Capstone S15\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mMiDaS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepth_loss\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_depth_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from train import train\n",
    "\n",
    "train(model, train_dataloader, device, yolo_args, midas_args, loss_weightage, model_save_path='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
