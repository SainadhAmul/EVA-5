{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final Model4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMTEOwGUbpDFBmgz7wuNzAa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MiggylgS7xka"},"source":["from __future__ import print_function\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim\r\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NERLnTNjOLQL"},"source":["# Train Phase transformations\r\n","train_transforms = transforms.Compose([\r\n","                                      #  transforms.Resize((28, 28)),\r\n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\r\n","                                       transforms.ToTensor(),\r\n","                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \r\n","                                       # Note the difference between (0.1307) and (0.1307,)\r\n","                                       ])\r\n","\r\n","# Test Phase transformations\r\n","test_transforms = transforms.Compose([\r\n","                                      #  transforms.Resize((28, 28)),\r\n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\r\n","                                       transforms.ToTensor(),\r\n","                                       transforms.Normalize((0.1307,), (0.3081,))\r\n","                                       ])\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3NfTt0uPHTB"},"source":["train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\r\n","test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"8ORChCB9PPBK","executionInfo":{"status":"ok","timestamp":1609588096223,"user_tz":-330,"elapsed":1880,"user":{"displayName":"Sainadh thikkireddi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCbt4_n-XUAv9hiK_BOWv5Kxa922Kfrmqnv95O7k=s64","userId":"16094823719727959916"}},"outputId":"cf55345f-e9bc-4d8c-bf02-887c923faa1e"},"source":["image, label = next(iter(train))\r\n","\r\n","import matplotlib.pyplot as plt\r\n","\r\n","plt.imshow(image.numpy().reshape(28,28),cmap = 'gray')\r\n","\r\n","print('LABEL : ' , label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LABEL :  5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qe5waWYgOLSS","executionInfo":{"status":"ok","timestamp":1609588096224,"user_tz":-330,"elapsed":1873,"user":{"displayName":"Sainadh thikkireddi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCbt4_n-XUAv9hiK_BOWv5Kxa922Kfrmqnv95O7k=s64","userId":"16094823719727959916"}},"outputId":"73358aa9-2d7f-4482-a26b-31df4c84fa7e"},"source":["SEED = 1\r\n","\r\n","# CUDA?\r\n","cuda = torch.cuda.is_available()\r\n","print(\"CUDA Available?\", cuda)\r\n","\r\n","# For reproducibility\r\n","torch.manual_seed(SEED)\r\n","\r\n","if cuda:\r\n","    torch.cuda.manual_seed(SEED)\r\n","\r\n","# dataloader arguments - something you'll fetch these from cmdprmt\r\n","dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\r\n","\r\n","# train dataloader\r\n","train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\r\n","\r\n","# test dataloader\r\n","test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CUDA Available? True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nE8SkOqXOLW6"},"source":["\r\n","class Net(nn.Module):\r\n","    def __init__(self):\r\n","        super(Net, self).__init__()\r\n","\r\n","        self.conv1 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(8),\r\n","            ) \r\n","        \r\n","        self.conv2 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(8),\r\n","            ) \r\n","\r\n","        self.conv3 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(16),\r\n","            ) \r\n","        \r\n","        self.conv4 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(16),\r\n","            ) \r\n","        \r\n","        self.pool  = nn.MaxPool2d(2, 2)\r\n","        \r\n","        self.conv6 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(16),\r\n","            ) \r\n","\r\n","        self.conv7 = nn.Sequential(\r\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(16),\r\n","            ) \r\n","        \r\n","        self.conv8 =  nn.Sequential(\r\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=1, bias=False),\r\n","            nn.ReLU(),            \r\n","            nn.BatchNorm2d(10),\r\n","            ) \r\n","        \r\n","        self.out = nn.AdaptiveAvgPool2d(1)\r\n","\r\n","    def forward(self,x):\r\n","\r\n","      x = self.conv1(x)\r\n","      x = self.conv2(x)\r\n","      x = self.conv3(x)\r\n","      x = self.conv4(x)\r\n","\r\n","      x = self.pool(x)\r\n","\r\n","      x = self.conv6(x)\r\n","      x = self.conv7(x)\r\n","      x = self.conv8(x)\r\n","      \r\n","      # print(x.)\r\n","      x = self.out(x)\r\n","      x = x.view(-1, 10)\r\n","\r\n","      return F.log_softmax(x, dim =1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQgdERLMC8Az"},"source":["# !pip install torchsummary\r\n","from torchsummary import summary\r\n","use_cuda = torch.cuda.is_available()\r\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQ5dzh88bxP7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609590773644,"user_tz":-330,"elapsed":799,"user":{"displayName":"Sainadh thikkireddi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCbt4_n-XUAv9hiK_BOWv5Kxa922Kfrmqnv95O7k=s64","userId":"16094823719727959916"}},"outputId":"ca90c43f-60cd-42ca-9fc0-a7bd44e817eb"},"source":["model = Net()\r\n","model = Net().to(device)\r\n","\r\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              72\n","              ReLU-2            [-1, 8, 28, 28]               0\n","       BatchNorm2d-3            [-1, 8, 28, 28]              16\n","            Conv2d-4            [-1, 8, 28, 28]             576\n","              ReLU-5            [-1, 8, 28, 28]               0\n","       BatchNorm2d-6            [-1, 8, 28, 28]              16\n","            Conv2d-7           [-1, 16, 28, 28]           1,152\n","              ReLU-8           [-1, 16, 28, 28]               0\n","       BatchNorm2d-9           [-1, 16, 28, 28]              32\n","           Conv2d-10           [-1, 16, 28, 28]           2,304\n","             ReLU-11           [-1, 16, 28, 28]               0\n","      BatchNorm2d-12           [-1, 16, 28, 28]              32\n","        MaxPool2d-13           [-1, 16, 14, 14]               0\n","           Conv2d-14           [-1, 16, 14, 14]           2,304\n","             ReLU-15           [-1, 16, 14, 14]               0\n","      BatchNorm2d-16           [-1, 16, 14, 14]              32\n","           Conv2d-17           [-1, 16, 14, 14]           2,304\n","             ReLU-18           [-1, 16, 14, 14]               0\n","      BatchNorm2d-19           [-1, 16, 14, 14]              32\n","           Conv2d-20           [-1, 10, 16, 16]             160\n","             ReLU-21           [-1, 10, 16, 16]               0\n","      BatchNorm2d-22           [-1, 10, 16, 16]              20\n","AdaptiveAvgPool2d-23             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 9,052\n","Trainable params: 9,052\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.09\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 1.12\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"obUexR42DGmh"},"source":["criterion = nn.CrossEntropyLoss()\r\n","optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6iIeK3H6bjD5","executionInfo":{"status":"ok","timestamp":1609590982584,"user_tz":-330,"elapsed":208308,"user":{"displayName":"Sainadh thikkireddi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgJCbt4_n-XUAv9hiK_BOWv5Kxa922Kfrmqnv95O7k=s64","userId":"16094823719727959916"}},"outputId":"b5c0cebf-85bb-44fc-a299-9231a477349c"},"source":["epochs = 15\r\n","\r\n","train_losses = []\r\n","test_losses = []\r\n","\r\n","train_correct = []\r\n","test_correct = []\r\n","\r\n","for i in range(epochs):\r\n","    \r\n","    correct_classified = 0\r\n","    for batch_number , (x_train,y_train) in enumerate(train_loader):\r\n","        \r\n","        batch_number+=1\r\n","        \r\n","        x_train,y_train = x_train.to(device), y_train.to(device)\r\n","\r\n","        # print(x_train.shape)\r\n","        pred = model.forward(x_train)\r\n","\r\n","        # print(pred.shape)\r\n","        # print(y_train.shape)\r\n","        loss = criterion(pred,y_train)\r\n","        \r\n","        #pred.argmax(dim=1, keepdim=True)\r\n","        #PyTorch .eq() function to do this, which compares the values in two tensors and if they match, returns a 1. If they donâ€™t match, it returns a 0:\r\n","        #correct += pred.eq(target.view_as(pred)).sum().item()\r\n","        predicted = torch.max(pred.data ,1)[1]\r\n","        correct_classified += (predicted == y_train).sum()\r\n","        \r\n","        optimizer.zero_grad()\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","        \r\n","        if batch_number%100 == 0:\r\n","            \r\n","            acc = round((correct_classified.item())/(batch_number*128),5)\r\n","            print(f'(TRAIN) Epoch: {i:4} batch_number: {batch_number:4} Loss : {loss:4.4} Acc : {acc:4.5}')\r\n","        \r\n","    train_losses.append(loss) \r\n","    train_correct.append(correct_classified)\r\n","    \r\n","    \r\n","    with torch.no_grad():\r\n","        \r\n","        test_loss = []\r\n","        correct_classified = 0\r\n","        for batch_number , (x_test,y_test) in enumerate(test_loader):\r\n","        \r\n","            x_test,y_test = x_test.to(device), y_test.to(device)\r\n","            pred = model.forward(x_test)\r\n","            loss = criterion(pred,y_test)\r\n","            test_losses.append(loss)\r\n","            \r\n","            correct_classified += (torch.max(pred,1)[1] == y_test).sum()\r\n","        \r\n","        avg_loss = torch.mean(torch.tensor(test_losses))\r\n","        test_losses.append(avg_loss)\r\n","        test_correct.append(correct_classified)\r\n","        \r\n","        acc = round(correct_classified.item()/10000,5)\r\n","        print('(TEST) Correct_classified : ' , correct_classified.item() ,' of 10000')\r\n","        print(f'(TEST) Epoch: {i:4} Loss : {avg_loss:4.4} Acc : {acc:4.5}')\r\n","        print('\\n','*'*60 , '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(TRAIN) Epoch:    0 batch_number:  100 Loss : 1.324 Acc : 0.73273\n","(TRAIN) Epoch:    0 batch_number:  200 Loss : 1.076 Acc : 0.82449\n","(TRAIN) Epoch:    0 batch_number:  300 Loss : 0.8917 Acc : 0.86169\n","(TRAIN) Epoch:    0 batch_number:  400 Loss : 0.7952 Acc : 0.88236\n","(TEST) Correct_classified :  9545  of 10000\n","(TEST) Epoch:    0 Loss : 0.7076 Acc : 0.9545\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    1 batch_number:  100 Loss : 0.6642 Acc : 0.95391\n","(TRAIN) Epoch:    1 batch_number:  200 Loss : 0.5711 Acc : 0.95578\n","(TRAIN) Epoch:    1 batch_number:  300 Loss : 0.4632 Acc : 0.95591\n","(TRAIN) Epoch:    1 batch_number:  400 Loss : 0.5005 Acc : 0.95689\n","(TEST) Correct_classified :  9642  of 10000\n","(TEST) Epoch:    1 Loss : 0.5804 Acc : 0.9642\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    2 batch_number:  100 Loss : 0.423 Acc : 0.96656\n","(TRAIN) Epoch:    2 batch_number:  200 Loss : 0.4595 Acc : 0.96461\n","(TRAIN) Epoch:    2 batch_number:  300 Loss : 0.3489 Acc : 0.96495\n","(TRAIN) Epoch:    2 batch_number:  400 Loss : 0.4188 Acc : 0.96561\n","(TEST) Correct_classified :  9694  of 10000\n","(TEST) Epoch:    2 Loss : 0.4974 Acc : 0.9694\n","\n"," ************************************************************ \n","\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"],"name":"stderr"},{"output_type":"stream","text":["(TRAIN) Epoch:    3 batch_number:  100 Loss : 0.3737 Acc : 0.97086\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"],"name":"stderr"},{"output_type":"stream","text":["(TRAIN) Epoch:    3 batch_number:  200 Loss : 0.2779 Acc : 0.9698\n","(TRAIN) Epoch:    3 batch_number:  300 Loss : 0.2651 Acc : 0.97047\n","(TRAIN) Epoch:    3 batch_number:  400 Loss : 0.3383 Acc : 0.97055\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"],"name":"stderr"},{"output_type":"stream","text":["(TEST) Correct_classified :  9739  of 10000\n","(TEST) Epoch:    3 Loss : 0.4363 Acc : 0.9739\n","\n"," ************************************************************ \n","\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"],"name":"stderr"},{"output_type":"stream","text":["(TRAIN) Epoch:    4 batch_number:  100 Loss : 0.3213 Acc : 0.97266\n","(TRAIN) Epoch:    4 batch_number:  200 Loss : 0.2351 Acc : 0.97262\n","(TRAIN) Epoch:    4 batch_number:  300 Loss : 0.2265 Acc : 0.97414\n","(TRAIN) Epoch:    4 batch_number:  400 Loss : 0.2119 Acc : 0.97434\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n","Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7f21097251d0>>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 1174, in _shutdown_workers\n","    if self._persistent_workers or self._workers_status[worker_id]:\n","AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"],"name":"stderr"},{"output_type":"stream","text":["(TEST) Correct_classified :  9757  of 10000\n","(TEST) Epoch:    4 Loss : 0.3911 Acc : 0.9757\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    5 batch_number:  100 Loss : 0.2275 Acc : 0.97383\n","(TRAIN) Epoch:    5 batch_number:  200 Loss : 0.1929 Acc : 0.97559\n","(TRAIN) Epoch:    5 batch_number:  300 Loss : 0.1492 Acc : 0.97654\n","(TRAIN) Epoch:    5 batch_number:  400 Loss : 0.1764 Acc : 0.97709\n","(TEST) Correct_classified :  9793  of 10000\n","(TEST) Epoch:    5 Loss : 0.3543 Acc : 0.9793\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    6 batch_number:  100 Loss : 0.1829 Acc : 0.97891\n","(TRAIN) Epoch:    6 batch_number:  200 Loss : 0.1228 Acc : 0.97813\n","(TRAIN) Epoch:    6 batch_number:  300 Loss : 0.1899 Acc : 0.97862\n","(TRAIN) Epoch:    6 batch_number:  400 Loss : 0.1418 Acc : 0.97895\n","(TEST) Correct_classified :  9786  of 10000\n","(TEST) Epoch:    6 Loss : 0.3244 Acc : 0.9786\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    7 batch_number:  100 Loss : 0.1194 Acc : 0.97898\n","(TRAIN) Epoch:    7 batch_number:  200 Loss : 0.1629 Acc : 0.97949\n","(TRAIN) Epoch:    7 batch_number:  300 Loss : 0.1269 Acc : 0.97997\n","(TRAIN) Epoch:    7 batch_number:  400 Loss : 0.09523 Acc : 0.98031\n","(TEST) Correct_classified :  9822  of 10000\n","(TEST) Epoch:    7 Loss : 0.3001 Acc : 0.9822\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    8 batch_number:  100 Loss : 0.1542 Acc : 0.97961\n","(TRAIN) Epoch:    8 batch_number:  200 Loss : 0.1244 Acc : 0.98094\n","(TRAIN) Epoch:    8 batch_number:  300 Loss : 0.1146 Acc : 0.98125\n","(TRAIN) Epoch:    8 batch_number:  400 Loss : 0.08701 Acc : 0.98133\n","(TEST) Correct_classified :  9825  of 10000\n","(TEST) Epoch:    8 Loss : 0.2797 Acc : 0.9825\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:    9 batch_number:  100 Loss : 0.1476 Acc : 0.98188\n","(TRAIN) Epoch:    9 batch_number:  200 Loss : 0.1162 Acc : 0.98246\n","(TRAIN) Epoch:    9 batch_number:  300 Loss : 0.131 Acc : 0.98247\n","(TRAIN) Epoch:    9 batch_number:  400 Loss : 0.09583 Acc : 0.98318\n","(TEST) Correct_classified :  9816  of 10000\n","(TEST) Epoch:    9 Loss : 0.262 Acc : 0.9816\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:   10 batch_number:  100 Loss : 0.1293 Acc : 0.98313\n","(TRAIN) Epoch:   10 batch_number:  200 Loss : 0.1101 Acc : 0.98352\n","(TRAIN) Epoch:   10 batch_number:  300 Loss : 0.08504 Acc : 0.98354\n","(TRAIN) Epoch:   10 batch_number:  400 Loss : 0.06779 Acc : 0.98346\n","(TEST) Correct_classified :  9858  of 10000\n","(TEST) Epoch:   10 Loss : 0.2466 Acc : 0.9858\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:   11 batch_number:  100 Loss : 0.08266 Acc : 0.98531\n","(TRAIN) Epoch:   11 batch_number:  200 Loss : 0.1169 Acc : 0.98496\n","(TRAIN) Epoch:   11 batch_number:  300 Loss : 0.09889 Acc : 0.98544\n","(TRAIN) Epoch:   11 batch_number:  400 Loss : 0.09426 Acc : 0.98525\n","(TEST) Correct_classified :  9836  of 10000\n","(TEST) Epoch:   11 Loss : 0.2334 Acc : 0.9836\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:   12 batch_number:  100 Loss : 0.1108 Acc : 0.98508\n","(TRAIN) Epoch:   12 batch_number:  200 Loss : 0.04644 Acc : 0.98586\n","(TRAIN) Epoch:   12 batch_number:  300 Loss : 0.1241 Acc : 0.98562\n","(TRAIN) Epoch:   12 batch_number:  400 Loss : 0.1014 Acc : 0.98564\n","(TEST) Correct_classified :  9841  of 10000\n","(TEST) Epoch:   12 Loss : 0.2218 Acc : 0.9841\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:   13 batch_number:  100 Loss : 0.05641 Acc : 0.9868\n","(TRAIN) Epoch:   13 batch_number:  200 Loss :  0.1 Acc : 0.9868\n","(TRAIN) Epoch:   13 batch_number:  300 Loss : 0.05239 Acc : 0.98685\n","(TRAIN) Epoch:   13 batch_number:  400 Loss : 0.06258 Acc : 0.98611\n","(TEST) Correct_classified :  9845  of 10000\n","(TEST) Epoch:   13 Loss : 0.2109 Acc : 0.9845\n","\n"," ************************************************************ \n","\n","(TRAIN) Epoch:   14 batch_number:  100 Loss : 0.06811 Acc : 0.98648\n","(TRAIN) Epoch:   14 batch_number:  200 Loss : 0.08134 Acc : 0.98734\n","(TRAIN) Epoch:   14 batch_number:  300 Loss : 0.05468 Acc : 0.98695\n","(TRAIN) Epoch:   14 batch_number:  400 Loss : 0.06604 Acc : 0.98713\n","(TEST) Correct_classified :  9860  of 10000\n","(TEST) Epoch:   14 Loss : 0.2012 Acc : 0.986\n","\n"," ************************************************************ \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7sSJ0Zzepdyy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiJM2rYA8Z2v"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0pvsgcnbjPL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaSk9Bw7OLZO"},"source":[""],"execution_count":null,"outputs":[]}]}